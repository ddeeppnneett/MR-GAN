mode: null
log_dir: null

data:
    name: cityscapes
    root: ./data/cityscapes/256x256
    num_workers: 32
    height: 256
    width: 256
    norm:
        mean: [0.3946, 0.2806, 0.3847]
        std: [0.2302, 0.1883, 0.2214]

    # to control training data size
    data_offset: null
    data_size: null

model:
    name: pix2pix

    # Architecture
    in_channels: 3
    out_channels: 3
    num_downs: 8  # 1/256
    num_features: 64
    pred_features: 64
    noise_type: gaussian
    noise_dim: [0, 0, 0, 0, 0, 0, 32, 32, 32]
    predictor: true
    norm: batch

    # Loss configurations
    mle:
        type: laplace
        options:
            order: 1
    gan:
        type: gan
        with_logits: true
    losses:
        base:
            recon_weight: 100.
            gan_weight: 1.
        pred:
        mm:
            mm_1st_weight: 0.0
            mm_2nd_weight: 0.0
            gan_weight: 1.0
            mle_weight: 10.0
            recon_weight: 0.0  # this converts optimize_g to BASE mode

batch_size: 16
num_mm: 8
num_mm_samples: 10

d_updates_per_step: 1
g_updates_per_step: 1

# Optimizers
d_optimizer:
    type: Adam
    options:
        lr: 0.0001
        betas: [0.5, 0.999]
        weight_decay: 0.0001
        amsgrad: True
    clip_grad:
        type: value
        options:
            clip_value: 0.5

g_optimizer:
    type: Adam
    options:
        lr: 0.0001
        betas: [0.5, 0.999]
        weight_decay: 0.0001
        amsgrad: True
    clip_grad:
        type: value
        options:
            clip_value: 0.5

p_optimizer:
    type: Adam
    options:
        lr: 0.0001
        betas: [0.5, 0.999]
        weight_decay: 0.0001
        amsgrad: True
    clip_grad:
        type: value
        options:
            clip_value: 0.5

e_optimizer:
    type: Adam
    options:
        lr: 0.0001
        betas: [0.5, 0.999]
        weight_decay: 0.0001
        amsgrad: True
    clip_grad:
        type: value
        options:
            clip_value: 0.5

# Learning rate schedulers
d_lr_scheduler:
g_lr_scheduler:
p_lr_scheduler:
e_lr_scheduler:

ckpt_step: 5000
summary_step: 1000

log_dispersion_min: -6.
log_dispersion_max: 0.

summary:
    train_samples: [466, 508, 788, 854, 1028, 1653, 1857, 2036, 2040, 2088, 2493, 2546, 2551, 2644, 2786, 2801]
    val_samples: [45, 114, 119, 160, 176, 206, 225, 367, 369, 398, 409, 422, 430, 431, 440, 458]
